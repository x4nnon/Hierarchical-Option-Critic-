/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.
  logger.warn(
/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:187: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.
  logger.warn(
/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: [33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`
  logger.warn(
/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:219: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. 
  logger.deprecation(
/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
global_step=416, ep_r=[0.], ep_l=[53]
global_step=440, ep_r=[0.], ep_l=[56]
global_step=544, ep_r=[0.], ep_l=[69]
global_step=600, ep_r=[0.], ep_l=[76]
global_step=656, ep_r=[2.], ep_l=[83]
global_step=688, ep_r=[0.], ep_l=[87]
global_step=904, ep_r=[0.], ep_l=[58]
global_step=912, ep_r=[0.], ep_l=[62]
global_step=920, ep_r=[0.], ep_l=[47]
global_step=992, ep_r=[0.], ep_l=[125]
global_step=1080, ep_r=[0.], ep_l=[53]
global_step=1104, ep_r=[0.], ep_l=[63]
global_step=1368, ep_r=[0.], ep_l=[58]
global_step=1400, ep_r=[1.], ep_l=[60]
global_step=1424, ep_r=[0.], ep_l=[43]
global_step=1512, ep_r=[4.], ep_l=[190]
global_step=1512, ep_r=[0.], ep_l=[75]
global_step=1768, ep_r=[0.], ep_l=[46]
global_step=1800, ep_r=[0.], ep_l=[47]
global_step=1848, ep_r=[1.], ep_l=[60]
global_step=1896, ep_r=[0.], ep_l=[113]
global_step=1912, ep_r=[0.], ep_l=[101]
global_step=1968, ep_r=[1.], ep_l=[160]
global_step=2016, ep_r=[0.], ep_l=[63]
Total loss: 4.858449935913086
global_step=2168, ep_r=[0.], ep_l=[50]
global_step=2232, ep_r=[0.], ep_l=[54]
global_step=2336, ep_r=[2.], ep_l=[61]
global_step=2536, ep_r=[0.], ep_l=[65]
global_step=2552, ep_r=[1.], ep_l=[48]
global_step=2736, ep_r=[0.], ep_l=[103]
global_step=2744, ep_r=[2.], ep_l=[154]
global_step=2800, ep_r=[0.], ep_l=[71]
global_step=2824, ep_r=[0.], ep_l=[61]
global_step=2904, ep_r=[0.], ep_l=[126]
global_step=3072, ep_r=[0.], ep_l=[67]
global_step=3192, ep_r=[1.], ep_l=[153]
global_step=3288, ep_r=[2.], ep_l=[58]
global_step=3376, ep_r=[0.], ep_l=[80]
global_step=3408, ep_r=[0.], ep_l=[76]
global_step=3600, ep_r=[0.], ep_l=[66]
global_step=3648, ep_r=[0.], ep_l=[93]
global_step=3736, ep_r=[0.], ep_l=[56]
global_step=3784, ep_r=[1.], ep_l=[47]
global_step=3904, ep_r=[0.], ep_l=[89]
Total loss: 3.896918296813965
global_step=4096, ep_r=[2.], ep_l=[169]
global_step=4128, ep_r=[0.], ep_l=[66]
global_step=4184, ep_r=[0.], ep_l=[101]
global_step=4208, ep_r=[1.], ep_l=[53]
global_step=4208, ep_r=[6.], ep_l=[207]
global_step=4232, ep_r=[4.], ep_l=[62]
global_step=4704, ep_r=[1.], ep_l=[59]
global_step=4704, ep_r=[0.], ep_l=[132]
global_step=4720, ep_r=[0.], ep_l=[67]
global_step=4824, ep_r=[0.], ep_l=[91]
global_step=4912, ep_r=[0.], ep_l=[98]
global_step=4928, ep_r=[1.], ep_l=[128]
global_step=4944, ep_r=[3.], ep_l=[92]
global_step=4992, ep_r=[2.], ep_l=[98]
global_step=5088, ep_r=[0.], ep_l=[48]
global_step=5224, ep_r=[0.], ep_l=[63]
global_step=5408, ep_r=[0.], ep_l=[62]
global_step=5544, ep_r=[3.], ep_l=[69]
global_step=5576, ep_r=[4.], ep_l=[61]
global_step=5696, ep_r=[1.], ep_l=[96]
global_step=5704, ep_r=[2.], ep_l=[125]
global_step=5888, ep_r=[0.], ep_l=[83]
global_step=5920, ep_r=[4.], ep_l=[122]
global_step=5984, ep_r=[1.], ep_l=[55]
global_step=6112, ep_r=[1.], ep_l=[67]
global_step=6136, ep_r=[2.], ep_l=[164]
Total loss: 4.163781642913818
global_step=6240, ep_r=[2.], ep_l=[40]
global_step=6320, ep_r=[0.], ep_l=[114]
global_step=6472, ep_r=[1.], ep_l=[61]
global_step=6560, ep_r=[0.], ep_l=[56]
global_step=6576, ep_r=[0.], ep_l=[86]
global_step=6744, ep_r=[1.], ep_l=[63]
global_step=6744, ep_r=[0.], ep_l=[53]
global_step=6824, ep_r=[4.], ep_l=[140]
global_step=6912, ep_r=[3.], ep_l=[152]
global_step=7048, ep_r=[2.], ep_l=[61]
global_step=7232, ep_r=[0.], ep_l=[82]
global_step=7240, ep_r=[0.], ep_l=[96]
global_step=7248, ep_r=[0.], ep_l=[63]
global_step=7432, ep_r=[0.], ep_l=[162]
global_step=7496, ep_r=[4.], ep_l=[94]
global_step=7560, ep_r=[4.], ep_l=[64]
global_step=7592, ep_r=[0.], ep_l=[85]
global_step=7776, ep_r=[0.], ep_l=[68]
global_step=7880, ep_r=[0.], ep_l=[79]
global_step=7960, ep_r=[0.], ep_l=[58]
global_step=8024, ep_r=[0.], ep_l=[54]
global_step=8048, ep_r=[3.], ep_l=[153]
global_step=8104, ep_r=[0.], ep_l=[84]
global_step=8144, ep_r=[3.], ep_l=[113]
Total loss: 3.6927990913391113
global_step=8312, ep_r=[0.], ep_l=[67]
global_step=8320, ep_r=[4.], ep_l=[95]
global_step=8688, ep_r=[0.], ep_l=[101]
global_step=8808, ep_r=[0.], ep_l=[88]
global_step=8880, ep_r=[7.], ep_l=[70]
global_step=9112, ep_r=[0.], ep_l=[53]
global_step=9144, ep_r=[4.], ep_l=[125]
global_step=9160, ep_r=[4.], ep_l=[139]
global_step=9232, ep_r=[0.], ep_l=[53]
global_step=9288, ep_r=[1.], ep_l=[158]
global_step=9376, ep_r=[2.], ep_l=[177]
global_step=9408, ep_r=[3.], ep_l=[66]
global_step=9648, ep_r=[0.], ep_l=[67]
global_step=9696, ep_r=[1.], ep_l=[58]
global_step=9776, ep_r=[1.], ep_l=[50]
global_step=9856, ep_r=[0.], ep_l=[56]
global_step=9904, ep_r=[0.], ep_l=[93]
global_step=9928, ep_r=[0.], ep_l=[35]
global_step=10136, ep_r=[2.], ep_l=[124]
global_step=10216, ep_r=[3.], ep_l=[55]
Total loss: 3.340958595275879
global_step=10304, ep_r=[9.], ep_l=[249]
global_step=10376, ep_r=[1.], ep_l=[85]
global_step=10392, ep_r=[0.], ep_l=[58]
global_step=10448, ep_r=[2.], ep_l=[74]
global_step=10600, ep_r=[2.], ep_l=[164]
global_step=10608, ep_r=[4.], ep_l=[59]
global_step=10616, ep_r=[1.], ep_l=[50]
global_step=10840, ep_r=[0.], ep_l=[67]
global_step=10896, ep_r=[0.], ep_l=[56]
global_step=10920, ep_r=[0.], ep_l=[66]
global_step=11096, ep_r=[1.], ep_l=[61]
global_step=11136, ep_r=[0.], ep_l=[95]
global_step=11152, ep_r=[0.], ep_l=[67]
global_step=11184, ep_r=[4.], ep_l=[160]
global_step=11304, ep_r=[1.], ep_l=[88]
global_step=11360, ep_r=[0.], ep_l=[65]
global_step=11448, ep_r=[0.], ep_l=[66]
global_step=11512, ep_r=[0.], ep_l=[45]
global_step=11560, ep_r=[3.], ep_l=[83]
global_step=11632, ep_r=[2.], ep_l=[67]
global_step=11896, ep_r=[1.], ep_l=[48]
global_step=12040, ep_r=[0.], ep_l=[85]
global_step=12072, ep_r=[2.], ep_l=[55]
global_step=12088, ep_r=[1.], ep_l=[98]
global_step=12120, ep_r=[1.], ep_l=[117]
global_step=12128, ep_r=[0.], ep_l=[124]
global_step=12136, ep_r=[0.], ep_l=[86]
global_step=12144, ep_r=[5.], ep_l=[73]
global_step=12240, ep_r=[1.], ep_l=[43]
Total loss: 1.1184836626052856
global_step=12368, ep_r=[0.], ep_l=[29]
global_step=12544, ep_r=[0.], ep_l=[50]
global_step=12608, ep_r=[0.], ep_l=[46]
global_step=12696, ep_r=[0.], ep_l=[82]
global_step=12824, ep_r=[0.], ep_l=[94]
global_step=12896, ep_r=[1.], ep_l=[96]
global_step=12904, ep_r=[0.], ep_l=[67]
global_step=13112, ep_r=[2.], ep_l=[63]
global_step=13136, ep_r=[4.], ep_l=[127]
global_step=13184, ep_r=[0.], ep_l=[45]
global_step=13216, ep_r=[0.], ep_l=[65]
global_step=13384, ep_r=[1.], ep_l=[162]
global_step=13440, ep_r=[0.], ep_l=[67]
global_step=13528, ep_r=[0.], ep_l=[52]
global_step=13616, ep_r=[1.], ep_l=[54]
global_step=13624, ep_r=[10.], ep_l=[135]
global_step=13752, ep_r=[0.], ep_l=[67]
global_step=13840, ep_r=[0.], ep_l=[57]
global_step=13920, ep_r=[2.], ep_l=[49]
global_step=13944, ep_r=[0.], ep_l=[63]
global_step=13976, ep_r=[0.], ep_l=[44]
global_step=13976, ep_r=[1.], ep_l=[45]
global_step=14008, ep_r=[1.], ep_l=[139]
global_step=14080, ep_r=[2.], ep_l=[118]
global_step=14288, ep_r=[0.], ep_l=[39]
global_step=14288, ep_r=[0.], ep_l=[67]
Total loss: 0.9315085411071777
global_step=14456, ep_r=[0.], ep_l=[64]
global_step=14464, ep_r=[0.], ep_l=[57]
global_step=14616, ep_r=[0.], ep_l=[97]
global_step=14624, ep_r=[2.], ep_l=[42]
global_step=14752, ep_r=[4.], ep_l=[97]
global_step=14752, ep_r=[0.], ep_l=[58]
global_step=14760, ep_r=[3.], ep_l=[105]
global_step=14944, ep_r=[0.], ep_l=[61]
global_step=14968, ep_r=[0.], ep_l=[63]
global_step=14984, ep_r=[2.], ep_l=[113]
global_step=15000, ep_r=[1.], ep_l=[47]
global_step=15144, ep_r=[1.], ep_l=[49]
global_step=15296, ep_r=[2.], ep_l=[67]
global_step=15360, ep_r=[1.], ep_l=[93]
global_step=15424, ep_r=[0.], ep_l=[57]
global_step=15448, ep_r=[0.], ep_l=[87]
global_step=15464, ep_r=[5.], ep_l=[58]
global_step=15640, ep_r=[0.], ep_l=[87]
global_step=15680, ep_r=[1.], ep_l=[48]
global_step=15768, ep_r=[0.], ep_l=[51]
global_step=15848, ep_r=[0.], ep_l=[108]
global_step=15920, ep_r=[0.], ep_l=[57]
global_step=15976, ep_r=[0.], ep_l=[66]
global_step=16176, ep_r=[0.], ep_l=[67]
global_step=16208, ep_r=[1.], ep_l=[98]
global_step=16216, ep_r=[3.], ep_l=[67]
global_step=16216, ep_r=[9.], ep_l=[134]
Total loss: 0.6370416879653931
global_step=16408, ep_r=[0.], ep_l=[29]
global_step=16480, ep_r=[0.], ep_l=[89]
global_step=16504, ep_r=[2.], ep_l=[73]
global_step=16656, ep_r=[0.], ep_l=[85]
global_step=16680, ep_r=[5.], ep_l=[58]
global_step=16800, ep_r=[4.], ep_l=[73]
global_step=16920, ep_r=[0.], ep_l=[52]
global_step=16936, ep_r=[1.], ep_l=[91]
global_step=16944, ep_r=[0.], ep_l=[67]
global_step=17080, ep_r=[1.], ep_l=[50]
global_step=17192, ep_r=[0.], ep_l=[67]
global_step=17280, ep_r=[3.], ep_l=[179]
global_step=17368, ep_r=[1.], ep_l=[56]
global_step=17456, ep_r=[2.], ep_l=[82]
global_step=17464, ep_r=[0.], ep_l=[65]
global_step=17488, ep_r=[1.], ep_l=[51]
global_step=17560, ep_r=[1.], ep_l=[135]
global_step=17728, ep_r=[0.], ep_l=[99]
global_step=17728, ep_r=[0.], ep_l=[67]
global_step=17760, ep_r=[1.], ep_l=[49]
global_step=17880, ep_r=[1.], ep_l=[49]
global_step=17896, ep_r=[0.], ep_l=[55]
global_step=17968, ep_r=[0.], ep_l=[63]
global_step=18008, ep_r=[0.], ep_l=[56]
global_step=18152, ep_r=[1.], ep_l=[109]
global_step=18184, ep_r=[1.], ep_l=[53]
global_step=18416, ep_r=[1.], ep_l=[67]
global_step=18416, ep_r=[0.], ep_l=[86]
Total loss: 0.8980582356452942
global_step=18464, ep_r=[0.], ep_l=[62]
global_step=18648, ep_r=[1.], ep_l=[115]
global_step=18656, ep_r=[4.], ep_l=[95]
global_step=18656, ep_r=[2.], ep_l=[59]
global_step=18728, ep_r=[1.], ep_l=[39]
global_step=18920, ep_r=[0.], ep_l=[96]
global_step=19000, ep_r=[0.], ep_l=[67]
global_step=19096, ep_r=[4.], ep_l=[55]
global_step=19232, ep_r=[0.], ep_l=[102]
global_step=19256, ep_r=[2.], ep_l=[66]
global_step=19256, ep_r=[2.], ep_l=[156]
global_step=19432, ep_r=[4.], ep_l=[97]
global_step=19512, ep_r=[0.], ep_l=[64]
global_step=19616, ep_r=[1.], ep_l=[65]
global_step=19648, ep_r=[0.], ep_l=[49]
global_step=19680, ep_r=[0.], ep_l=[95]
global_step=19712, ep_r=[0.], ep_l=[57]
global_step=19768, ep_r=[0.], ep_l=[67]
global_step=19896, ep_r=[0.], ep_l=[58]
global_step=19920, ep_r=[1.], ep_l=[38]
global_step=19992, ep_r=[3.], ep_l=[168]
global_step=20008, ep_r=[0.], ep_l=[62]
global_step=20048, ep_r=[1.], ep_l=[50]
global_step=20272, ep_r=[0.], ep_l=[44]
global_step=20304, ep_r=[0.], ep_l=[67]
global_step=20408, ep_r=[3.], ep_l=[64]
global_step=20424, ep_r=[1.], ep_l=[54]
global_step=20440, ep_r=[1.], ep_l=[91]
global_step=20456, ep_r=[1.], ep_l=[51]
Total loss: 0.6641101241111755
global_step=20544, ep_r=[0.], ep_l=[108]
global_step=20544, ep_r=[0.], ep_l=[67]
global_step=20824, ep_r=[2.], ep_l=[69]
global_step=20856, ep_r=[1.], ep_l=[54]
global_step=20880, ep_r=[1.], ep_l=[53]
global_step=21000, ep_r=[0.], ep_l=[87]
global_step=21072, ep_r=[0.], ep_l=[83]
global_step=21088, ep_r=[0.], ep_l=[68]
global_step=21144, ep_r=[0.], ep_l=[88]
global_step=21224, ep_r=[1.], ep_l=[50]
global_step=21248, ep_r=[0.], ep_l=[46]
global_step=21344, ep_r=[0.], ep_l=[100]
global_step=21496, ep_r=[0.], ep_l=[62]
global_step=21592, ep_r=[1.], ep_l=[65]
global_step=21600, ep_r=[0.], ep_l=[57]
global_step=21600, ep_r=[1.], ep_l=[93]
global_step=21624, ep_r=[1.], ep_l=[50]
global_step=21624, ep_r=[0.], ep_l=[67]
global_step=21632, ep_r=[0.], ep_l=[48]
global_step=22000, ep_r=[0.], ep_l=[63]
global_step=22016, ep_r=[1.], ep_l=[49]
global_step=22048, ep_r=[1.], ep_l=[52]
global_step=22208, ep_r=[0.], ep_l=[108]
global_step=22320, ep_r=[0.], ep_l=[90]
global_step=22320, ep_r=[0.], ep_l=[87]
global_step=22376, ep_r=[4.], ep_l=[98]
global_step=22400, ep_r=[0.], ep_l=[48]
global_step=22440, ep_r=[1.], ep_l=[49]
global_step=22496, ep_r=[0.], ep_l=[62]
Total loss: 0.23586603999137878
global_step=22752, ep_r=[0.], ep_l=[54]
global_step=22832, ep_r=[4.], ep_l=[54]
global_step=22848, ep_r=[1.], ep_l=[51]
global_step=22896, ep_r=[0.], ep_l=[162]
global_step=22968, ep_r=[0.], ep_l=[95]
global_step=23000, ep_r=[0.], ep_l=[63]
global_step=23160, ep_r=[4.], ep_l=[98]
global_step=23232, ep_r=[0.], ep_l=[48]
global_step=23240, ep_r=[1.], ep_l=[51]
global_step=23264, ep_r=[0.], ep_l=[64]
global_step=23376, ep_r=[0.], ep_l=[60]
global_step=23512, ep_r=[0.], ep_l=[64]
global_step=23608, ep_r=[1.], ep_l=[161]
global_step=23648, ep_r=[1.], ep_l=[52]
global_step=23648, ep_r=[1.], ep_l=[51]
global_step=23760, ep_r=[0.], ep_l=[99]
global_step=23800, ep_r=[0.], ep_l=[67]
global_step=23816, ep_r=[1.], ep_l=[82]
global_step=24008, ep_r=[0.], ep_l=[62]
global_step=24024, ep_r=[0.], ep_l=[47]
global_step=24024, ep_r=[0.], ep_l=[52]
global_step=24032, ep_r=[1.], ep_l=[48]
global_step=24152, ep_r=[1.], ep_l=[97]
global_step=24328, ep_r=[0.], ep_l=[66]
global_step=24424, ep_r=[1.], ep_l=[50]
global_step=24456, ep_r=[1.], ep_l=[53]
global_step=24464, ep_r=[1.], ep_l=[81]
global_step=24544, ep_r=[0.], ep_l=[67]
Total loss: 0.22754956781864166
global_step=24600, ep_r=[0.], ep_l=[56]
global_step=24720, ep_r=[3.], ep_l=[120]
global_step=24736, ep_r=[0.], ep_l=[89]
global_step=24816, ep_r=[0.], ep_l=[61]
global_step=24832, ep_r=[1.], ep_l=[51]
global_step=24872, ep_r=[1.], ep_l=[52]
global_step=25024, ep_r=[4.], ep_l=[70]
global_step=25048, ep_r=[0.], ep_l=[63]
global_step=25240, ep_r=[1.], ep_l=[51]
global_step=25280, ep_r=[1.], ep_l=[51]
global_step=25352, ep_r=[1.], ep_l=[94]
global_step=25352, ep_r=[0.], ep_l=[67]
global_step=25496, ep_r=[0.], ep_l=[97]
global_step=25512, ep_r=[1.], ep_l=[97]
global_step=25536, ep_r=[0.], ep_l=[61]
global_step=25656, ep_r=[1.], ep_l=[52]
global_step=25680, ep_r=[2.], ep_l=[82]
global_step=25680, ep_r=[1.], ep_l=[50]
global_step=25808, ep_r=[0.], ep_l=[57]
global_step=25888, ep_r=[0.], ep_l=[67]
global_step=26032, ep_r=[0.], ep_l=[62]
global_step=26048, ep_r=[1.], ep_l=[49]
global_step=26064, ep_r=[0.], ep_l=[48]
global_step=26072, ep_r=[1.], ep_l=[49]
global_step=26224, ep_r=[0.], ep_l=[52]
global_step=26280, ep_r=[0.], ep_l=[96]
global_step=26296, ep_r=[0.], ep_l=[100]
global_step=26328, ep_r=[1.], ep_l=[32]
global_step=26424, ep_r=[0.], ep_l=[67]
global_step=26448, ep_r=[1.], ep_l=[50]
global_step=26536, ep_r=[0.], ep_l=[63]
Total loss: 0.4296051263809204
global_step=26728, ep_r=[1.], ep_l=[50]
global_step=26832, ep_r=[1.], ep_l=[48]
global_step=26960, ep_r=[0.], ep_l=[67]
global_step=26984, ep_r=[2.], ep_l=[115]
global_step=27008, ep_r=[0.], ep_l=[98]
global_step=27032, ep_r=[0.], ep_l=[94]
global_step=27072, ep_r=[0.], ep_l=[67]
global_step=27088, ep_r=[0.], ep_l=[99]
global_step=27240, ep_r=[1.], ep_l=[51]
global_step=27304, ep_r=[3.], ep_l=[72]
global_step=27448, ep_r=[1.], ep_l=[55]
global_step=27496, ep_r=[0.], ep_l=[67]
global_step=27608, ep_r=[0.], ep_l=[67]
global_step=27624, ep_r=[0.], ep_l=[80]
global_step=27632, ep_r=[1.], ep_l=[49]
global_step=27816, ep_r=[0.], ep_l=[98]
global_step=27848, ep_r=[0.], ep_l=[95]
global_step=27904, ep_r=[0.], ep_l=[57]
global_step=28016, ep_r=[0.], ep_l=[48]
global_step=28032, ep_r=[0.], ep_l=[67]
global_step=28144, ep_r=[3.], ep_l=[105]
global_step=28144, ep_r=[0.], ep_l=[67]
global_step=28272, ep_r=[0.], ep_l=[57]
global_step=28336, ep_r=[0.], ep_l=[54]
global_step=28408, ep_r=[1.], ep_l=[49]
global_step=28464, ep_r=[4.], ep_l=[105]
global_step=28568, ep_r=[0.], ep_l=[67]
global_step=28624, ep_r=[0.], ep_l=[97]
global_step=28632, ep_r=[0.], ep_l=[61]
global_step=28656, ep_r=[0.], ep_l=[64]
Total loss: -0.10792085528373718
global_step=28792, ep_r=[0.], ep_l=[48]
global_step=28792, ep_r=[0.], ep_l=[57]
global_step=29024, ep_r=[1.], ep_l=[49]
global_step=29056, ep_r=[0.], ep_l=[98]
global_step=29096, ep_r=[0.], ep_l=[79]
global_step=29104, ep_r=[0.], ep_l=[67]
global_step=29192, ep_r=[0.], ep_l=[67]
global_step=29208, ep_r=[1.], ep_l=[52]
global_step=29208, ep_r=[0.], ep_l=[52]
global_step=29400, ep_r=[0.], ep_l=[97]
global_step=29424, ep_r=[1.], ep_l=[50]
global_step=29504, ep_r=[0.], ep_l=[56]
global_step=29584, ep_r=[0.], ep_l=[47]
global_step=29632, ep_r=[0.], ep_l=[66]
global_step=29640, ep_r=[0.], ep_l=[54]
global_step=29648, ep_r=[3.], ep_l=[69]
global_step=29888, ep_r=[0.], ep_l=[87]
global_step=29936, ep_r=[2.], ep_l=[64]
global_step=29960, ep_r=[0.], ep_l=[57]
global_step=30008, ep_r=[1.], ep_l=[53]
global_step=30040, ep_r=[0.], ep_l=[49]
global_step=30136, ep_r=[0.], ep_l=[92]
Traceback (most recent call last):
  File "/home/x4nno_desktop/Documents/HOC/methods/HOC.py", line 581, in <module>
    main_training_loop(agent, args, writer, envs, device)
  File "/home/x4nno_desktop/Documents/HOC/methods/HOC.py", line 532, in main_training_loop
    option_termination_probs = agent.termination_function_option(next_obs, current_options)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 280, in termination_function_option
    termination_prob = self.option_termination[i](state_rep[mask])
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 123, in forward
    x = F.relu(self.fc1(state_rep))
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1675, in __getattr__
    def __getattr__(self, name: str) -> Any:
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/x4nno_desktop/Documents/HOC/methods/HOC.py", line 581, in <module>
    main_training_loop(agent, args, writer, envs, device)
  File "/home/x4nno_desktop/Documents/HOC/methods/HOC.py", line 532, in main_training_loop
    option_termination_probs = agent.termination_function_option(next_obs, current_options)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 280, in termination_function_option
    termination_prob = self.option_termination[i](state_rep[mask])
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 123, in forward
    x = F.relu(self.fc1(state_rep))
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1675, in __getattr__
    def __getattr__(self, name: str) -> Any:
KeyboardInterrupt