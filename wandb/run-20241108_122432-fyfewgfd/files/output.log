/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:174: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.
  logger.warn(
/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:187: UserWarning: [33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.
  logger.warn(
/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:195: UserWarning: [33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`
  logger.warn(
/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:219: DeprecationWarning: [33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. 
  logger.deprecation(
/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(done, (bool, np.bool8)):
global_step=144, ep_r=[0.], ep_l=[19]
global_step=408, ep_r=[0.], ep_l=[52]
global_step=504, ep_r=[0.], ep_l=[64]
global_step=520, ep_r=[3.], ep_l=[66]
global_step=640, ep_r=[0.], ep_l=[81]
global_step=648, ep_r=[0.], ep_l=[63]
global_step=696, ep_r=[0.], ep_l=[88]
global_step=760, ep_r=[1.], ep_l=[96]
global_step=952, ep_r=[0.], ep_l=[120]
global_step=1048, ep_r=[2.], ep_l=[66]
global_step=1088, ep_r=[3.], ep_l=[73]
global_step=1152, ep_r=[0.], ep_l=[64]
global_step=1256, ep_r=[2.], ep_l=[106]
global_step=1280, ep_r=[1.], ep_l=[79]
global_step=1512, ep_r=[0.], ep_l=[102]
global_step=1632, ep_r=[2.], ep_l=[73]
global_step=1648, ep_r=[2.], ep_l=[70]
global_step=1744, ep_r=[0.], ep_l=[58]
global_step=1808, ep_r=[0.], ep_l=[82]
global_step=1976, ep_r=[4.], ep_l=[90]
global_step=1976, ep_r=[1.], ep_l=[128]
Traceback (most recent call last):
  File "/home/x4nno_desktop/Documents/HOC/methods/HOC.py", line 360, in <module>
    main_training_loop(agent, args, writer, envs, device)
  File "/home/x4nno_desktop/Documents/HOC/methods/HOC.py", line 322, in main_training_loop
    total_loss = agent.update_function(batch, args, writer, global_step_truth, envs)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 423, in update_function
    termination_probs_meta = self.termination_function_meta(b_states, b_meta_options)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 314, in termination_function_meta
    state_rep = self.forward_state_rep(state)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 125, in forward
    x = self.conv(x)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 7.75 GiB of which 413.44 MiB is free. Including non-PyTorch memory, this process has 7.07 GiB memory in use. Of the allocated memory 6.82 GiB is allocated by PyTorch, and 86.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home/x4nno_desktop/Documents/HOC/methods/HOC.py", line 360, in <module>
    main_training_loop(agent, args, writer, envs, device)
  File "/home/x4nno_desktop/Documents/HOC/methods/HOC.py", line 322, in main_training_loop
    total_loss = agent.update_function(batch, args, writer, global_step_truth, envs)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 423, in update_function
    termination_probs_meta = self.termination_function_meta(b_states, b_meta_options)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 314, in termination_function_meta
    state_rep = self.forward_state_rep(state)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/x4nno_desktop/Documents/HOC/OC_agents/HOC_agent.py", line 125, in forward
    x = self.conv(x)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/x4nno_desktop/anaconda3/envs/fracos_ppo/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 7.75 GiB of which 413.44 MiB is free. Including non-PyTorch memory, this process has 7.07 GiB memory in use. Of the allocated memory 6.82 GiB is allocated by PyTorch, and 86.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)